# Protocol
Communication compromises two different scenarios: communication between clients and servers to initiate calls and communication directly between clients during video calls.

## Server - Client communication
Upon launch, client will connect to server, spawning an independent recevier thread to listen for messages from server (e.g. incoming calls). Client will enter a daemon input thread waiting on user action. When user A wants to call user B, user A must pass user B's ip and port, this will be sent as a request to the server which will attempt to inform user B that user A wishes to call. User B will receive this request and be able to accept or reject. Two options are available for what follows: 1) User A since initiating the call request has been listening for input from User B and sending frames/data to user B, user B accepts the call simply by spawning threads to listen on port (fixed by design) and beginning to send frames/data to user A on his ip/port. 2) User B sends a response to the server. If user B rejects the call, the server informs user A and communication is finished. If user B accepts, the server will inform user A of acceptance by providing a unix timestamp at which point user A and user B will begin sending frames/data to each other.

## Client - Client Communication
Upon agreement to call, user A (and B likewise) will have four separate main threads as well as two sets of processing threads. Main threads are as follows:
1. Listener Thread: listens on port 8000 for incoming calibration frames and on port 8001 for incoming feature data. Stores any received data to the raw_recv buffer in order (with metadata of frameid?)
2. Constructor Threads (multiple): wait for data to fill in raw_recv buffer, for a single frame perform delaunay triangulation and store data to fin_recv buffer. Run multiple parallel processes, i.e. construct 5-10 frames in parallel from buffer.
3. Render Thread: checks fin_recv buffer for finished frames to display and queues these to UI (cv2 window) to output
4. Capture Thread: stores raw frames from video camera capture to raw_send buffer (with metadata of frameid?)
5. Extractor Threads (multiple): wait for data to fill in raw_send buffer, for each frame perform dlib facial feature recognition and store resulting 68 features into fin_send buffer, based on frameid store raw frame in fin_send to send as calibration frame. Run multiple parallel process, i.e. extract facial features from 5-10 frames in parallel.
6. Sender Thread: Based on frameid, send raw frame stored in fin_send as calibration frame, and send 68 features for each frame from fin_send buffer. 

### Client State
Global client state includes the following in four categories of video and caller info, incoming call state, outgoing call state and general:
- Video and Caller Info:
    - Calibration Frame Refresh Rate
    - Resolution of Frames
    - Caller IP
    - Caller Port Number
- Call State:
    - Incoming (bool) ~ am I waiting on user input to respond to incoming call
    - Outgoing (bool) ~ am I waiting on response from server (from other user) on outgoing call
    - Accepted (bool) ~ have I accepted incoming call or has other user accepted my outgoing call
    - Calling (bool) ~ have I started threads to actually video call

### Metadata

#### Server - Client Communication

Each call will be assigned a random 10 digit ID. This ID is generated by initiang client and used to track that call.

#### Client - Client Communication

Each picture frame and feature data frame must have metadata of frameid. Assuming a maximum call time of 1 hour, with 30fps, the frameid will be bounded by 110,000 which will not take up any space to represent.

### Buffers

Based on TCP guarantee to send all packets in order, must simply ensure that for sending packets that those are in order in fin_send buffer. For receiving, must simply ensure that all packets in order in fin_recv buffer before rendering. Thus, only requirement is that fin_send buffer and fin_recv buffer be linked list style sorted by frameid.

### Headers

#### Server - Client Communication

Each message has a header consisting of 4 characters:
- Operation (1 character): 0 for request, 1 for response
- Message Type (1 character): 'C' for initiating a call, 'A' for accepting a call, 'R' for rejecting
- Status (1 character): 0 for OK, 1 for Failure (TODO: Add more error types)
- Payload Length (3 characters): Length of payload in two character format e.g. 1 - '01'. Represents payload length in number of bytes.

#### Client - Client Communication
- Operation (1 character): 0 for request, 1 for response
- Message Type (1 character): 'F' for calibration frame, 'D' for feature data of frame, 'E' to end call
- Status (1 character): 0 for OK, 1 for Failure (TODO: Add more error types)
- Frame Number (7 characters): Frame Number/ID in 7 character format e.g. Frame ID 1 - '0000001', for 'E' type '0000000'
- Chunk Number (5 characters): Chunk Number for data of frame specified by frame number in 5 character format e.g. chunk number 1 - '00001', for 'E' type '00000'
- Payload Length (5 characters): Length of payload in five character format e.g. 1 - '00001', for 'E' type '00000'. Represents payload length in number of bytes.

### Payload

#### Server - Client Communication

Can contain user names and call ID. Values are separated using comma delimiter. Payload contains data in the following order: for type 'C', call ID, initiator name, initiator ip, initiator port. For type 'A' or 'R', call ID, responder name, unix timestamp sync.

#### Client - Client Communication

Contains bytes of chunk of frame (either actual calibration picture frame or 68 features in JSON format?). TODO: how to reconstruct data from sent into usable format.

## Next Steps
1. Audio to be added using separate buffers and threads (no complex processing)
2. For conferencing, different communication model with server will be required (can still use complex processing to reduce bandwidth)